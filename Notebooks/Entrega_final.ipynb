{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e726fc1c-f755-4f2a-8c02-202e4bd8ce3e",
   "metadata": {},
   "source": [
    "## Resumen del Proyecto\n",
    "\n",
    "Este proyecto tiene como objetivo analizar el clima de opinión digital en torno al Plebiscito Nacional de Chile de 2020 y compararlo con los resultados oficiales de la votación (SERVEL). En la entrega anterior, se realizó una exploración inicial de los datos recolectados de Twitter (ahora X), identificando tendencias temporales y patrones de interacción.\n",
    "\n",
    "En esta nueva etapa, recolcetamos nuevamente tweets, esta vez los pudimos convertir a csv, y avanzamos hacia el modelamiento predictivo. \n",
    "Utilizamos técnicas de Procesamiento de Lenguaje Natural (NLP) y Aprendizaje Supervisado para clasificar automáticamente la postura política de los tweets (\"Apruebo\" vs. \"Rechazo\") y estimar la representatividad de la discusión en redes sociales frente a la realidad electoral. La hipótesis central previo a crear nuestro modelo de prediccion es que las redes sociales pueden haber funcionado como una \"cámara de eco\", sobrerrepresentando ciertas posturas en comparación con el voto popular.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac486886-100e-43fb-b8f6-9810d2d14e32",
   "metadata": {},
   "source": [
    "## 2. Análisis de Datos\n",
    "\n",
    "### 2.1 Metodología y Seleccion de los Datos\n",
    "Para este análisis, se utilizaron como principal fuente de información:\n",
    "\n",
    "Datos de Entrenamiento (Ground Truth): Se construyó un dataset etiquetado combinando tweets provenientes de archivos temáticos específicos (apruebo.csv y rechazo_campaña.csv). Esto permitió contar con ejemplos claros de cada postura para entrenar al modelo.\n",
    "\n",
    "### 2.2 Preprocesamientos y Seleccion de Variables\n",
    "\n",
    "Dado que la información principal es texto no estructurado, se aplicaron las siguientes transformaciones\n",
    "Limpieza de Texto: Se eliminaron valores nulos y duplicados para asegurar la calidad de los datos.\n",
    "Vectorización TF-IDF: Se transformó el texto en una matriz numérica utilizando TF-IDF (Term Frequency - Inverse Document Frequency).\n",
    "\n",
    "### 2.3 Selección del Modelo y Configuración\n",
    "\n",
    "Se eligió un modelo de Regresión Logística para la tarea de clasificación binaria.\n",
    "\n",
    "Justificación:\n",
    "\n",
    "Interpretabilidad: La regresión logística permite analizar los coeficientes para entender qué palabras \"empujan\" la predicción hacia una clase u otra.\n",
    "\n",
    "Eficiencia: Es computacionalmente ligera y funciona muy bien con matrices dispersas de texto como las generadas por TF-IDF.\n",
    "\n",
    "Manejo de Desbalance: Se utilizó el parámetro class_weight='balanced' para corregir automáticamente el desbalance natural en los datos (donde la opción \"Apruebo\" tenía muchas más muestras que el \"Rechazo\"), asegurando que el modelo no ignorara la clase minoritaria.\n",
    "\n",
    "### 2.4 Análisis No Supervisado (PCA)\n",
    "Complementariamente, se aplicó un Análisis de Componentes Principales (PCA) para reducir la dimensionalidad de 3,000 a 2 componentes, para así tambien permitir visualizar en un plano cartesiano si los discursos del \"Apruebo\" y \"Rechazo\" eran semánticamente distinguibles.\n",
    "\n",
    "Resultado: El gráfico de dispersión no mostró una separación clara generalmente, mostrando que los temas en comun y el tipo de lenguaje era compartido, pero aun asi habian ciertso casos donde se ve la separación,  confirmando que tambien existen vocabularios distintivos para cada opción, aunque comparten temáticas transversales.\n",
    "\n",
    "### 2.6 Predicción Final y Comparación\n",
    "\n",
    "Finalmente, el modelo entrenado se aplicó a la totalidad de los tweets recolectados para estimar la distribución de opinión en la plataforma.\n",
    "\n",
    "Resultado del Modelo: \n",
    "Apruebo: 83.24%\n",
    "Rechazo: 16.76%\n",
    "\n",
    "Comparación con la Realidad: Al contrastar esto con los datos del SERVEL (78% Apruebo), se evidenció una discrepancia significativa, sugiriendo una sobre-representación del discurso del Apruebo en Twitter durante el periodo estudiado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7187c5b2-fb30-4732-bea0-dcc567fa4cc4",
   "metadata": {},
   "source": [
    "## 3. Analisis de Resultados\n",
    "La pregunta central que guio esta parte del análisis fue la de predicción:\n",
    "\n",
    "Predicción: ¿Puede la intensidad y polarización del discurso en redes sociales predecir, al menos parcialmente, la proporción de votos de un candidato o el nivel de participación en un plebiscito?. \"Realizaremos un análisis comparativo entre la actividad y el sentimiento expresado en redes sociales sobre las opciones 'Apruebo' y 'Rechazo', y contrastar dichos datos con los resultados electorales oficiales publicados por el SERVEL para el plebiscito.\"\n",
    "\n",
    "Tras aplicar el modelo de Regresión Logística entrenado sobre la totalidad de los datos recolectados, los resultados indican que la conversación digital en Twitter estuvo alineada, aunque con una ligera sobreestimación, con el resultado electoral real.\n",
    "\n",
    "Predicción del Modelo: El análisis de sentimiento y postura política en Twitter proyectó un 83.24% de apoyo a la opción \"Apruebo\" y un 16.76% para el \"Rechazo\".\n",
    "\n",
    "Resultado Real (SERVEL): Los datos oficiales muestran que el \"Apruebo\" obtuvo un 78.31% de los votos, mientras que el \"Rechazo\" alcanzó un 21.69\n",
    "\n",
    "La diferencia entre la proyección digital y la realidad fue de 4.93 puntos porcentuales. Esto sugiere que, contrario a la primera hipótesis que nos planteabamos al empezar esta predicción, que era el de una \"cámara de eco\" desconectada de la realidad, en este caso particular, el clima de opinión en Twitter fue un termómetro razonablemente preciso del consenso nacional, aunque con una leve tendencia a amplificar la opción mayoritaria\n",
    "La desviación de casi 5 puntos a favor del \"Apruebo\" en los tweets creemos que puede atribuirse al activismo digital más intenso de los grupos jóvenes, quienes tienden a ser más progresistas y  suelen tener una mayor presencia y actividad en redes sociales en comparación con los segmentos demográficos más conservadores o de mayor edad."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d34a86-e972-4360-b6fd-8d59106f8619",
   "metadata": {},
   "source": [
    "## 4. ¿Que podría salir mal?\n",
    "A pesar de que el modelo logró una predicción cercana al resultado del SERVEL, asumir que las redes sociales son un espejo fiel de la sociedad conlleva riesgos significativos. A continuación, se detallan las limitaciones técnicas y los dilemas éticos identificados en este proyecto y en esta etapa.\n",
    "\n",
    "### Sesgos de los Datos (Sesgo de Selección y Representatividad)\n",
    "Brecha Digital y Demográfica: Los usuarios de Twitter tienden a ser más jóvenes, urbanos y con mayor nivel educativo que el votante promedio. Esto explica por qué nuestro modelo sobreestimó el \"Apruebo\" (83% vs 78% real): es probable que el segmento demográfico más conservador o de mayor edad (que tiende a votar más Rechazo) esté subrepresentado en la plataforma.\n",
    "Otro problema es que nuestro análisis solo está capturando a quienes escriben tweets. Ignora a la gran masa de usuarios pasivos (\"lurkers\") y a quienes no tienen acceso a internet. Basar decisiones políticas solo en este análisis invisibilizaría a las poblaciones más vulnerables o desconectadas.\n",
    "\n",
    "### Limitaciones Metodologicas\n",
    "El problema del NLP\n",
    "Incapacidad de detectar Ironía y Sarcasmo: El modelo de Regresión Logística utilizado se basa en la presencia de palabras clave. No comprende el contexto y eso dificulta el proceso de clasificación. Un tweet sarcástico como \"Qué gran idea destruir la economía, #Apruebo\" sería clasificado incorrectamente como apoyo positivo debido a las palabras \"gran\" y \"Apruebo\".\n",
    "Otro problema fue que asumimos que los usuarios que no usan hashtags hablan igual que los militantes que sí los usan. Esta suposición puede ser falsa; el votante indeciso suele usar un lenguaje más moderado o ambiguo que el modelo podría malinterpretar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412a5c78-7b0a-4b49-b91b-90d496244a7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
